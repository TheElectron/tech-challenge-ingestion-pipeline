# ğŸ“–  ğŸ“ˆ Data Pipeline: IngestÃ£o e AnÃ¡lise de Dados | FIAP Tech Challenge #02

![PySpark]
![AWS]
![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![License](https://img.shields.io/badge/license-MIT-lightgrey.svg)

## ğŸ’» DescriÃ§Ã£o do Projeto

Este projeto implementa um pipeline de dados *serverless* na AWS, e foi desenvolvido para o **Tech Challenge #02** da PÃ³s-GraduaÃ§Ã£o em  **Machine Learning Engineering** da FIAP.

Seu objetivo Ã© extrair, processar e disponibilizar os dados da Carteira do Dia da bolsa de valores brasileira (B3), utilizando o AWS Glue e disponibilizÃ¡-los para consultas via Amazon Athena.

## ğŸ¢ Arquitetura

A soluÃ§Ã£o segue uma arquitetura *serverless* orientada a eventos, com foco no baixo custo e escalabilidade.

Fluxograma

                    !!!!FAZER A PORRA DO DESENHO!!!!!!

IngestÃ£o: Um script Python extrai dados da B3 e salva em formato Parquet no S3 (Camada Raw).

OrquestraÃ§Ã£o: O upload do arquivo no S3 dispara automaticamente uma funÃ§Ã£o Lambda.

Processamento: A Lambda inicia um Job no AWS Glue (Visual), que realiza limpeza, cÃ¡lculos de data e agregaÃ§Ãµes.

Armazenamento: O Glue salva os dados refinados no S3 (Camada Refined), particionados por data e ticker.

Consumo: O Glue Catalog mantÃ©m os metadados atualizados, permitindo consultas SQL via Amazon Athena.


## ğŸ“‚ Estrutura do Projeto


```
b3-data-pipeline/
â”œâ”€â”€ docs/                   # Diagramas e documentaÃ§Ã£o complementar
â”œâ”€â”€ infrastructure/         # Infraestrutura como CÃ³digo (IaC)
â”‚   â””â”€â”€ terraform/          # Scripts para provisionar S3, IAM, Glue e Lambda
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/          # Scripts de extraÃ§Ã£o (Scraper B3)
â”‚   â”œâ”€â”€ lambdas/            # CÃ³digo da Lambda Trigger
â”‚   â”œâ”€â”€ glue/               # DefiniÃ§Ãµes do Job Visual e Scripts PySpark
â”‚   â””â”€â”€ sql/                # Queries de validaÃ§Ã£o para o Athena
â”œâ”€â”€ requirements.txt        # DependÃªncias do projeto
â””â”€â”€ README.md               # DocumentaÃ§Ã£o principal
```


## ğŸš€ Como Executar

1. PrÃ©-requisitos
Conta AWS ativa.

AWS CLI configurado localmente.

Terraform instalado (v1.0+).

Python 3.9+.

2. Provisionamento da Infraestrutura
Utilizamos Terraform para criar todos os recursos necessÃ¡rios.

Bash

cd infrastructure/terraform
terraform init
terraform plan
terraform apply
Isso criarÃ¡ o Bucket S3, as Roles de IAM, a Lambda Trigger e o esqueleto do Job Glue.