# üìà B3 Data Pipeline: Ingest√£o e An√°lise de Dados | FIAP Tech Challenge #02

![AWS](https://img.shields.io/badge/AWS-232F3E?style=for-the-badge&logo=amazon-aws&logoColor=white)
![PySpark](https://img.shields.io/badge/PySpark-E25A1C?style=for-the-badge&logo=apache-spark&logoColor=white)
![Python](https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Terraform](https://img.shields.io/badge/Terraform-7B42BC?style=for-the-badge&logo=terraform&logoColor=white)
![License](https://img.shields.io/badge/license-MIT-lightgrey.svg?style=for-the-badge)

## üíª Descri√ß√£o do Projeto

Este projeto consiste em um pipeline de engenharia de dados orientado a eventos (*event-driven* ) para extra√ß√£o, processamento e an√°lise da composi√ß√£o do √≠ndice IBOVESPA (B3).

Desenvolvida como entrega final do **Tech Challenge #02** da P√≥s-Gradua√ß√£o em **Machine Learning Engineering** da FIAP, a solu√ß√£o utiliza o ecossistema AWS para criar um Data Lake escal√°vel. O fluxo extrai diariamente a carteira te√≥rica da B3, ingere os dados brutos, processa m√©tricas financeiras complexas (como M√©dia M√≥vel e Volatilidade) e disponibiliza as informa√ß√µes para consulta anal√≠tica via SQL.

## üè¢ Arquitetura

A solu√ß√£o segue uma arquitetura *serverless*, priorizando o desacoplamento de componentes, baixo custo operacional e escalabilidade autom√°tica.

### Fluxo de Dados

O fluxo de dados segue o padr√£o Medallion (Bronze/Silver):

```mermaid
flowchart TD
    %% Defini√ß√£o de Estilos
    classDef aws fill:#FF9900,stroke:#232F3E,stroke-width:2px,color:white;
    classDef storage fill:#3F8624,stroke:#232F3E,stroke-width:2px,color:white;
    classDef external fill:#999999,stroke:#232F3E,stroke-width:2px,color:white;
    classDef trigger fill:#E7157B,stroke:#232F3E,stroke-width:2px,color:white;

    %% Fontes e Agendador
    subgraph Origem ["Fonte de Dados Externos"]
        B3[API Web B3<br/>Hidden JSON]:::external
    end

    Scheduler(EventBridge<br/>Scheduler Di√°rio):::trigger

    %% Camada de Ingest√£o
    subgraph Bronze ["Camada Raw (Bronze)"]
        GlueExt[Glue Job: Extra√ß√£o<br/>Python Shell]:::aws
        S3Raw[(S3 Bucket<br/>/raw<br/>dt=YYYY-MM-DD)]:::storage
    end

    %% Camada de Orquestra√ß√£o
    subgraph Orchestration ["Orquestra√ß√£o de Eventos"]
        S3Event>S3 Event PUT<br/>Notification]:::trigger
        Lambda[Lambda Function<br/>Trigger Glue]:::aws
    end

    %% Camada de Processamento
    subgraph Silver ["Camada Refined (Silver)"]
        GlueTrans[Glue Job: Transforma√ß√£o<br/>Apache Spark ETL]:::aws
        S3Ref[(S3 Bucket<br/>/refined<br/>dt=, ticker=)]:::storage
        Catalog[Glue Data Catalog<br/>Database & Tables]:::aws
    end

    %% Camada de Consumo
    subgraph Serving ["Camada de Consumo"]
        Athena[Amazon Athena<br/>SQL Queries]:::aws
        Analista((Analista<br/>Usu√°rio))
    end

    %% Fluxo Principal
    Scheduler -->|1. Dispara √†s 18h| GlueExt
    GlueExt -- "2. HTTPS GET" --> B3
    B3 -- JSON --> GlueExt
    GlueExt -- "3. Salva Parquet (Limpa & Escreve)" --> S3Raw

    S3Raw -.->|4. Detecta novo arquivo| S3Event
    S3Event -->|5. Aciona| Lambda
    Lambda -- "6. Inicia Job com Argumentos<br/>(--JOB_DATE, --BUCKET)" --> GlueTrans

    GlueTrans -- "7. L√™ Janela Hist√≥rica<br/>(Dia atual + 6 dias anteriores)" --> S3Raw
    GlueTrans -- "8. Aplica Regras<br/>(M√©dia M√≥vel, Volatilidade)" --> GlueTrans
    GlueTrans -- "9. Salva Parquet Particionado" --> S3Ref
    GlueTrans -- "10. Atualiza Metadados" --> Catalog

    %% Fluxo de Consulta
    Analista -->|SQL| Athena
    Athena -->|Consulta Esquema| Catalog
    Athena -->|L√™ Dados| S3Ref

    %% Linkagem de Estilos
    linkStyle 0,3,5,6,7,9,10 stroke:#FF9900,stroke-width:2px;
    linkStyle 4,8 stroke:#3F8624,stroke-width:2px;
    linkStyle 11,12,13 stroke:#232F3E,stroke-width:1px,stroke-dasharray: 5 5;

    
- Raw Layer (Bronze):
    Respons√°vel pela ingest√£o. O Job Glue (extract_b3_data.py) realiza a engenharia reversa da API da B3, extraindo os dados da carteira do dia e armazenando-os em formato Parquet com particionamento di√°rio (dt=YYYY-MM-DD).

    >üí° Optou-se pelo uso de um Jog Glue do tipo Python Shell nesta etapa. Como a tarefa simples, apenas requisi√ß√µes HTTP, n√£o exige √© necess√°rio o uso de processamento distribu√≠do. Essa escolha reduz drasticamente os custos operacionais (DPU) em compara√ß√£o a um cluster Spark convencional.

- Orquestra√ß√£o:
    Utiliza-se o padr√£o Event Notification. Ao concluir a grava√ß√£o do arquivo na Raw Layer, o S3 dispara uma AWS Lambda, que identifica a data da carga e aciona o job de transforma√ß√£o.

- Refined Layer (Silver):
    O Job Glue (transform_b3_data.py) utiliza Apache Spark para aplicar regras de neg√≥cio, limpeza e c√°lculos de janelamento (Window Functions).

    Os dados processados s√£o catalogados automaticamente no AWS Glue Data Catalog, tornando-os imediatamente dispon√≠veis para consultas SQL via Amazon Athena.

## üõ†Ô∏è Tecnologias Utilizadas

- Linguagens: Python 3.9, PySpark.
- Armazenamento: AWS S3 (com particionamento Hive).
- Computa√ß√£o (ETL):
    AWS Glue Python Shell (Extra√ß√£o).
    AWS Glue Spark (Transforma√ß√£o).
- Orquestra√ß√£o: AWS Lambda & Amazon EventBridge.
- Analytics: Amazon Athena.
- IaC: Terraform (V√´m ai, confia ...).

## üìÇ Estrutura do Projeto

```
b3-data-pipeline/
‚îú‚îÄ‚îÄ docs/                   # Diagramas e documenta√ß√£o complementar
‚îú‚îÄ‚îÄ infrastructure/         # Infraestrutura como C√≥digo (IaC)
‚îÇ   ‚îî‚îÄ‚îÄ terraform/          # Scripts para provisionar S3, IAM, Glue e Lambda
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/          # Scripts de extra√ß√£o (Scraper B3)
‚îÇ   ‚îú‚îÄ‚îÄ lambdas/            # C√≥digo da Lambda Trigger
‚îÇ   ‚îú‚îÄ‚îÄ glue/               # Defini√ß√µes do Job Visual e Scripts PySpark
‚îÇ   ‚îî‚îÄ‚îÄ sql/                # Queries de valida√ß√£o para o Athena
‚îú‚îÄ‚îÄ requirements.txt        # Depend√™ncias do projeto
‚îî‚îÄ‚îÄ README.md               # Documenta√ß√£o principal
```

## ‚öôÔ∏è Detalhes da Implementa√ß√£o

### 1. Camada de Extra√ß√£o (extract_b3_data.py)
- Tipo: Glue Job (Python Shell).
- Estrat√©gia: Engenharia reversa da API oculta do site da B3 para obter dados limpos em JSON, evitando instabilidade de scraping HTML.
- Idempot√™ncia: Implementada l√≥gica de "Limpeza pr√©via" (delete_objects) para garantir que reprocessamentos no mesmo dia n√£o dupliquem dados.
- Sa√≠da: Arquivos Parquet na pasta s3://bucket/raw/dt=YYYY-MM-DD/.

### 2. Gatilho de Orquestra√ß√£o (trigger_transform.py)
- Tipo: AWS Lambda.
- Trigger: S3 PUT Event.
- Fun√ß√£o: Detecta novos arquivos na pasta RAW, extrai a data da parti√ß√£o e injeta como argumento din√¢mico (--JOB_DATE) no Job de Transforma√ß√£o.

### 3. Camada de Transforma√ß√£o (transform_b3_data.py)
- Tipo: Glue Job (Spark ETL).
- L√≥gica de Janela (Window Functions):
- Leitura: Carrega hist√≥rico (D-6) para permitir c√°lculos temporais.
- M√©dia M√≥vel (7d): Suaviza√ß√£o da participa√ß√£o do ativo.
- Volatilidade: Desvio padr√£o da participa√ß√£o no per√≠odo.
- Otimiza√ß√£o: Uso de .cache() e Filtros de Parti√ß√£o (Partition Pruning) para leitura eficiente.
- Sa√≠da: Tabela particionada (dt, ticker) registrada no Glue Catalog.

<!-- üöÄ Como Executar

1. Pr√©-requisitos
Conta AWS ativa.

AWS CLI configurado localmente.

Terraform instalado (v1.0+).

Python 3.9+.

2. Provisionamento da Infraestrutura
Utilizamos Terraform para criar todos os recursos necess√°rios.

Bash

cd infrastructure/terraform
terraform init
terraform plan
terraform apply
Isso criar√° o Bucket S3, as Roles de IAM, a Lambda Trigger e o esqueleto do Job Glue. -->