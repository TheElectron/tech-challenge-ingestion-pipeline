# ğŸ“ˆ B3 Data Pipeline: IngestÃ£o e AnÃ¡lise de Dados | FIAP Tech Challenge #02

![AWS](https://img.shields.io/badge/AWS-232F3E?style=for-the-badge&logo=amazon-aws&logoColor=white)
![PySpark](https://img.shields.io/badge/PySpark-E25A1C?style=for-the-badge&logo=apache-spark&logoColor=white)
![Python](https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Terraform](https://img.shields.io/badge/Terraform-7B42BC?style=for-the-badge&logo=terraform&logoColor=white)
![License](https://img.shields.io/badge/license-MIT-lightgrey.svg?style=for-the-badge)

## ğŸ’» DescriÃ§Ã£o do Projeto

Este projeto consiste em um pipeline de engenharia de dados orientado a eventos (*event-driven* ) para extraÃ§Ã£o, processamento e anÃ¡lise da composiÃ§Ã£o do Ã­ndice IBOVESPA (B3).

Desenvolvida como entrega final do **Tech Challenge #02** da PÃ³s-GraduaÃ§Ã£o em **Machine Learning Engineering** da FIAP, a soluÃ§Ã£o utiliza o ecossistema AWS para criar um Data Lake escalÃ¡vel. O fluxo extrai diariamente a carteira teÃ³rica da B3, ingere os dados brutos, processa mÃ©tricas financeiras complexas (como MÃ©dia MÃ³vel e Volatilidade) e disponibiliza as informaÃ§Ãµes para consulta analÃ­tica via SQL.

## ğŸ¢ Arquitetura

A soluÃ§Ã£o segue uma arquitetura *serverless*, priorizando o desacoplamento de componentes, baixo custo operacional e escalabilidade automÃ¡tica.

### Fluxo de Dados

flowchart LR
    A[B3 Website] -->|ExtraÃ§Ã£o DiÃ¡ria| B(Glue Job: Extract)
    B -->|Parquet| C[(S3: Raw Zone)]
    C -->|Trigger Event| D(AWS Lambda)
    D -->|Start Job + Args| E(Glue Job: Transform)
    E -->|Read Window| C
    E -->|Parquet + Catalog| F[(S3: Refined Zone)]
    F -->|Query| G[Amazon Athena]


O fluxo de dados segue o padrÃ£o Medallion (Bronze/Silver):
'''
flowchart TD
    %% DefiniÃ§Ã£o de Estilos
    classDef aws fill:#FF9900,stroke:#232F3E,stroke-width:2px,color:white;
    classDef storage fill:#3F8624,stroke:#232F3E,stroke-width:2px,color:white;
    classDef external fill:#999999,stroke:#232F3E,stroke-width:2px,color:white;
    classDef trigger fill:#E7157B,stroke:#232F3E,stroke-width:2px,color:white;
    %% Fontes e Agendador
    subgraph Origem ["Fonte de Dados Externos"]
        B3[API Web B3\n(Hidden JSON)]:::external
    end
    Scheduler(EventBridge\nScheduler DiÃ¡rio):::trigger
    %% Camada de IngestÃ£o
    subgraph Bronze ["Camada Raw (Bronze)"]
        GlueExt[Glue Job: ExtraÃ§Ã£o\nPython Shell]:::aws
        S3Raw[(S3 Bucket\n/raw\ndt=YYYY-MM-DD)]:::storage
    end
    %% Camada de OrquestraÃ§Ã£o
    subgraph Orchestration ["OrquestraÃ§Ã£o de Eventos"]
        S3Event>S3 Event PUT\nNotification]:::trigger
        Lambda[Lambda Function\nTrigger Glue]:::aws
    end
    %% Camada de Processamento
    subgraph Silver ["Camada Refined (Silver)"]
        GlueTrans[Glue Job: TransformaÃ§Ã£o\nApache Spark ETL]:::aws
        S3Ref[(S3 Bucket\n/refined\ndt=, ticker=)]:::storage
        Catalog[Glue Data Catalog\nDatabase & Tables]:::aws
    end
    %% Camada de Consumo
    subgraph Serving ["Camada de Consumo"]
        Athena[Amazon Athena\nSQL Queries]:::aws
        Analista((Analista\nUsuÃ¡rio))
    end
    %% Fluxo Principal
    Scheduler -->|1. Dispara Ã s 18h| GlueExt
    GlueExt -- "2. HTTPS GET" --> B3
    B3 -- JSON --> GlueExt
    GlueExt -- "3. Salva Parquet (Limpa & Escreve)" --> S3Raw
    S3Raw -.->|4. Detecta novo arquivo| S3Event
    S3Event -->|5. Aciona| Lambda
    Lambda -- "6. Inicia Job com Argumentos\n(--JOB_DATE, --BUCKET)" --> GlueTrans
    GlueTrans -- "7. LÃª Janela HistÃ³rica\n(Dia atual + 6 dias anteriores)" --> S3Raw
    GlueTrans -- "8. Aplica Regras\n(MÃ©dia MÃ³vel, Volatilidade)" --> GlueTrans
    GlueTrans -- "9. Salva Parquet Particionado" --> S3Ref
    GlueTrans -- "10. Atualiza Metadados" --> Catalog
    %% Fluxo de Consulta
    Analista -->|SQL| Athena
    Athena -->|Consulta Esquema| Catalog
    Athena -->|LÃª Dados| S3Ref
    %% Linkagem de Estilos
    linkStyle 0,3,5,6,7,9,10 stroke:#FF9900,stroke-width:2px;
    linkStyle 4,8 stroke:#3F8624,stroke-width:2px;
    linkStyle 11,12,13 stroke:#232F3E,stroke-width:1px,stroke-dasharray: 5 5;
'''

- Raw Layer (Bronze):
    ResponsÃ¡vel pela ingestÃ£o. O Job Glue (extract_b3_data.py) realiza a engenharia reversa da API da B3, extraindo os dados da carteira do dia e armazenando-os em formato Parquet com particionamento diÃ¡rio (dt=YYYY-MM-DD).

    >ğŸ’¡ Optou-se pelo uso de um Jog Glue do tipo Python Shell nesta etapa. Como a tarefa simples, apenas requisiÃ§Ãµes HTTP, nÃ£o exige Ã© necessÃ¡rio o uso de processamento distribuÃ­do. Essa escolha reduz drasticamente os custos operacionais (DPU) em comparaÃ§Ã£o a um cluster Spark convencional.

- OrquestraÃ§Ã£o:
    Utiliza-se o padrÃ£o Event Notification. Ao concluir a gravaÃ§Ã£o do arquivo na Raw Layer, o S3 dispara uma AWS Lambda, que identifica a data da carga e aciona o job de transformaÃ§Ã£o.

- Refined Layer (Silver):
    O Job Glue (transform_b3_data.py) utiliza Apache Spark para aplicar regras de negÃ³cio, limpeza e cÃ¡lculos de janelamento (Window Functions).

    Os dados processados sÃ£o catalogados automaticamente no AWS Glue Data Catalog, tornando-os imediatamente disponÃ­veis para consultas SQL via Amazon Athena.

## ğŸ› ï¸ Tecnologias Utilizadas

- Linguagens: Python 3.9, PySpark.
- Armazenamento: AWS S3 (com particionamento Hive).
- ComputaÃ§Ã£o (ETL):
    AWS Glue Python Shell (ExtraÃ§Ã£o).
    AWS Glue Spark (TransformaÃ§Ã£o).
- OrquestraÃ§Ã£o: AWS Lambda & Amazon EventBridge.
- Analytics: Amazon Athena.
- IaC: Terraform (VÃ«m ai, confia ...).

## ğŸ“‚ Estrutura do Projeto

```
b3-data-pipeline/
â”œâ”€â”€ docs/                   # Diagramas e documentaÃ§Ã£o complementar
â”œâ”€â”€ infrastructure/         # Infraestrutura como CÃ³digo (IaC)
â”‚   â””â”€â”€ terraform/          # Scripts para provisionar S3, IAM, Glue e Lambda
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/          # Scripts de extraÃ§Ã£o (Scraper B3)
â”‚   â”œâ”€â”€ lambdas/            # CÃ³digo da Lambda Trigger
â”‚   â”œâ”€â”€ glue/               # DefiniÃ§Ãµes do Job Visual e Scripts PySpark
â”‚   â””â”€â”€ sql/                # Queries de validaÃ§Ã£o para o Athena
â”œâ”€â”€ requirements.txt        # DependÃªncias do projeto
â””â”€â”€ README.md               # DocumentaÃ§Ã£o principal
```

## âš™ï¸ Detalhes da ImplementaÃ§Ã£o

### 1. Camada de ExtraÃ§Ã£o (extract_b3_data.py)
- Tipo: Glue Job (Python Shell).
- EstratÃ©gia: Engenharia reversa da API oculta do site da B3 para obter dados limpos em JSON, evitando instabilidade de scraping HTML.
- IdempotÃªncia: Implementada lÃ³gica de "Limpeza prÃ©via" (delete_objects) para garantir que reprocessamentos no mesmo dia nÃ£o dupliquem dados.
- SaÃ­da: Arquivos Parquet na pasta s3://bucket/raw/dt=YYYY-MM-DD/.

### 2. Gatilho de OrquestraÃ§Ã£o (trigger_transform.py)
- Tipo: AWS Lambda.
- Trigger: S3 PUT Event.
- FunÃ§Ã£o: Detecta novos arquivos na pasta RAW, extrai a data da partiÃ§Ã£o e injeta como argumento dinÃ¢mico (--JOB_DATE) no Job de TransformaÃ§Ã£o.

### 3. Camada de TransformaÃ§Ã£o (transform_b3_data.py)
- Tipo: Glue Job (Spark ETL).
- LÃ³gica de Janela (Window Functions):
- Leitura: Carrega histÃ³rico (D-6) para permitir cÃ¡lculos temporais.
- MÃ©dia MÃ³vel (7d): SuavizaÃ§Ã£o da participaÃ§Ã£o do ativo.
- Volatilidade: Desvio padrÃ£o da participaÃ§Ã£o no perÃ­odo.
- OtimizaÃ§Ã£o: Uso de .cache() e Filtros de PartiÃ§Ã£o (Partition Pruning) para leitura eficiente.
- SaÃ­da: Tabela particionada (dt, ticker) registrada no Glue Catalog.

<!-- ğŸš€ Como Executar

1. PrÃ©-requisitos
Conta AWS ativa.

AWS CLI configurado localmente.

Terraform instalado (v1.0+).

Python 3.9+.

2. Provisionamento da Infraestrutura
Utilizamos Terraform para criar todos os recursos necessÃ¡rios.

Bash

cd infrastructure/terraform
terraform init
terraform plan
terraform apply
Isso criarÃ¡ o Bucket S3, as Roles de IAM, a Lambda Trigger e o esqueleto do Job Glue. -->